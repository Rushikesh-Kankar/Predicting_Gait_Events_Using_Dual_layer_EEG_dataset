{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05adbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "def apply_pca_to_raw(raw, max_components):\n",
    "    data = raw.get_data().T\n",
    "    pca = PCA(n_components=max_components)\n",
    "    transformed_data = pca.fit_transform(data)\n",
    "    \n",
    "    # Create new channel names for PCA components\n",
    "    new_ch_names = [f'PCA{str(i+1)}' for i in range(max_components)]\n",
    "    \n",
    "    # Create a new raw object with the transformed data\n",
    "    info = mne.create_info(ch_names=new_ch_names, sfreq=raw.info['sfreq'], ch_types='eeg')\n",
    "    raw_pca = mne.io.RawArray(transformed_data.T, info)\n",
    "    \n",
    "    return raw_pca\n",
    "\n",
    "\n",
    "def find_continuous_no_event_epochs(events, raw, num_ulhs):\n",
    "    event_id_no_event = {'no_event': 0}\n",
    "\n",
    "    event_df = pd.DataFrame(events[0], columns=['Sample Number', 'Offset', 'Event ID'])\n",
    "    event_name_dict = events[1]  \n",
    "    reverse_dict = {v: k for k, v in event_name_dict.items()}\n",
    "    event_df['Event Name'] = event_df['Event ID'].map(reverse_dict)\n",
    "\n",
    "    unperturbed_frame = event_df.loc[event_df['Event Name'].isin(['ULHS', 'URTO', 'URHS', 'ULTO','ULP_On'])] \n",
    "\n",
    "    # Sort by Sample Number\n",
    "    unperturbed_frame = unperturbed_frame.sort_values('Sample Number')\n",
    "\n",
    "    # Get the sample numbers\n",
    "    sample_numbers = unperturbed_frame['Sample Number'].values\n",
    "\n",
    "    middle_samples = []\n",
    "    # For each pair of consecutive sample numbers in the unperturbed frame\n",
    "    for i in range(len(sample_numbers) - 1):\n",
    "        # If the difference is larger than 53\n",
    "        if sample_numbers[i+1] - sample_numbers[i] > 53:\n",
    "            # Get the middle sample number\n",
    "            middle_sample = (sample_numbers[i] + sample_numbers[i+1]) // 2\n",
    "            middle_samples.append(middle_sample)\n",
    "\n",
    "    # Randomly select middle samples\n",
    "    if len(middle_samples) > num_ulhs:\n",
    "        middle_samples = random.sample(middle_samples, num_ulhs)\n",
    "\n",
    "    # Create epochs for the selected middle samples\n",
    "    continuous_no_event_epochs_list = []\n",
    "    for middle_sample in middle_samples:\n",
    "        new_events = np.array([[middle_sample, 0, 0]])\n",
    "        continuous_no_event_epochs_list.append(\n",
    "            mne.Epochs(raw, new_events, event_id=event_id_no_event, tmin=-0.05, tmax=0.05, event_repeated='merge', baseline=(None,0))\n",
    "        )\n",
    "\n",
    "    return continuous_no_event_epochs_list\n",
    "\n",
    "\n",
    "def get_max_pca_components(subject_ids, file_path, use_78_channels=False):\n",
    "    max_components = 0\n",
    "    pc_count_dict = {}\n",
    "\n",
    "    for sub_id in subject_ids:\n",
    "        # Load the data from the .set file\n",
    "        full_path = file_path.format(sub_id=sub_id)\n",
    "        if 'allwalk_EEG.set' in full_path:\n",
    "            if use_78_channels:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "                # extract good channels\n",
    "                mat_file = scipy.io.loadmat(f'DATA/EEG_ICA_STRUCT/PTW{sub_id}_allwalk_EEG_ICA_STRUCT_rejbadchannels_diverse_incr_comps.mat')\n",
    "                good_channels = mat_file['EEG_ICA_STRUCT']['good_chans'][0][0][0]\n",
    "                # randomly select 78 good channels\n",
    "                np.random.seed(42) \n",
    "                selected_channels = np.random.choice(good_channels, size=78, replace=False)\n",
    "                # Save the selected channel names to a file\n",
    "                with open(f'{save_dir}/selected_channel_names_{sub_id}.txt', 'w') as f:\n",
    "                    for channel in selected_channels:\n",
    "                        f.write(f'{channel}\\n')\n",
    "                raw.pick_channels([raw.ch_names[i] for i in selected_channels - 1])\n",
    "                # rename the channels to the same names\n",
    "                channel_names = ['ch' + str(i+1) for i in range(len(raw.ch_names))]\n",
    "                raw.rename_channels(dict(zip(raw.ch_names, channel_names)))\n",
    "                \n",
    "            else:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "\n",
    "            # Calculate PCA components after preprocessing\n",
    "            data = raw.get_data().T\n",
    "            pca = PCA(n_components=0.95)\n",
    "            pca.fit(data)\n",
    "            \n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#             for i, variance in enumerate(explained_variance):\n",
    "#                 print(f\"Component {i+1}: {variance:.5f} variance explained\")\n",
    "            \n",
    "#             cumulative_variance_at_20 = sum(pca.explained_variance_ratio_[:20])\n",
    "#             print(f\"Cumulative variance at component 20: {cumulative_variance_at_20:.5f}\")\n",
    "\n",
    "\n",
    "            max_components = max(max_components, pca.n_components_)\n",
    "            pc_count_dict[sub_id] = pca.n_components_\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            # Plotting the cumulative sum of explained variance ratio\n",
    "            explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            plt.plot(explained_variance)\n",
    "            plt.xlabel('Number of components')\n",
    "            plt.ylabel('Cumulative explained variance')\n",
    "            plt.title(f'Subject {sub_id}: Cumulative Explained Variance by Components')\n",
    "            plt.tight_layout()\n",
    "            ax = plt.gca()  # Get the current axis\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "            plt.savefig(f'{save_dir}/{sub_id}.png')\n",
    "            plt.close()\n",
    "            \n",
    "        elif 'allwalk_artifact.set' in full_path:\n",
    "            \n",
    "            if use_78_channels:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "                np.random.seed(42)\n",
    "                # randomly select 78 channels\n",
    "                selected_channels = np.random.choice(raw.ch_names, size=78, replace=False)\n",
    "                raw.pick_channels(selected_channels)\n",
    "                # Save the selected channel names to a file\n",
    "                with open(f'{save_dir}/selected_channel_names_{sub_id}.txt', 'w') as f:\n",
    "                    for channel in selected_channels:\n",
    "                        f.write(f'{channel}\\n')\n",
    "                # rename the channels to the same names\n",
    "                channel_names = ['ch' + str(i+1) for i in range(len(raw.ch_names))]\n",
    "                raw.rename_channels(dict(zip(raw.ch_names, channel_names)))\n",
    "\n",
    "\n",
    "            else:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "            \n",
    "          # Calculate PCA components after preprocessing\n",
    "            data = raw.get_data().T\n",
    "            pca = PCA(n_components=0.95)\n",
    "            pca.fit(data)\n",
    "            \n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#             for i, variance in enumerate(explained_variance):\n",
    "#                 print(f\"Component {i+1}: {variance:.5f} variance explained\")\n",
    "            \n",
    "#             cumulative_variance_at_20 = sum(pca.explained_variance_ratio_[:20])\n",
    "#             print(f\"Cumulative variance at component 20: {cumulative_variance_at_20:.5f}\")\n",
    "\n",
    "\n",
    "            max_components = max(max_components, pca.n_components_)\n",
    "            pc_count_dict[sub_id] = pca.n_components_\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            # Plotting the cumulative sum of explained variance ratio\n",
    "            explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            plt.plot(explained_variance)\n",
    "            plt.xlabel('Number of components')\n",
    "            plt.ylabel('Cumulative explained variance')\n",
    "            plt.title(f'Subject {sub_id}: Cumulative Explained Variance by Components')\n",
    "            plt.tight_layout()\n",
    "            ax = plt.gca()  # Get the current axis\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "            plt.savefig(f'{save_dir}/{sub_id}.png')\n",
    "            plt.close()\n",
    "            \n",
    "        else:\n",
    "            print(f'File path for subject {sub_id} is invalid')\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(list(pc_count_dict.items()), columns=['Subject ID', 'Number of PCs'])\n",
    "    df.to_csv('num_pcs.csv', index=False)\n",
    "\n",
    "    return max_components\n",
    "\n",
    "\n",
    "def preprocess_eeg_data(subject_ids, file_path, event_id, save_dir, use_78_channels=False,use_pca_for_epoching=False):\n",
    "    # Create an empty list to store the preprocessed EEG data for each subject\n",
    "    eeg_data = []\n",
    "    continuous_no_event_epochs_list_all=[]\n",
    "    pc_count_dict = {}\n",
    "    max_components = get_max_pca_components(subject_ids, file_path, use_78_channels)\n",
    "    \n",
    "    for sub_id in subject_ids:\n",
    "        # Load the data from the .set file\n",
    "        full_path = file_path.format(sub_id=sub_id)\n",
    "        if 'allwalk_EEG.set' in full_path:\n",
    "            if use_78_channels:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "                # extract good channels\n",
    "                mat_file = scipy.io.loadmat(f'DATA/EEG_ICA_STRUCT/PTW{sub_id}_allwalk_EEG_ICA_STRUCT_rejbadchannels_diverse_incr_comps.mat')\n",
    "                good_channels = mat_file['EEG_ICA_STRUCT']['good_chans'][0][0][0]\n",
    "                # randomly select 78 good channels\n",
    "                np.random.seed(42)\n",
    "                selected_channels = np.random.choice(good_channels, size=78, replace=False)\n",
    "                # Save the selected channel names to a file\n",
    "                with open(f'{save_dir}/selected_channel_names_{sub_id}.txt', 'w') as f:\n",
    "                    for channel in selected_channels:\n",
    "                        f.write(f'{channel}\\n')\n",
    "                raw.pick_channels([raw.ch_names[i] for i in selected_channels - 1])\n",
    "                # rename the channels to the same names\n",
    "                channel_names = ['ch' + str(i+1) for i in range(len(raw.ch_names))]\n",
    "                raw.rename_channels(dict(zip(raw.ch_names, channel_names)))\n",
    "                \n",
    "\n",
    "            else:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "            \n",
    "            events = mne.events_from_annotations(raw)\n",
    "            events1 = events[:1][0]\n",
    "\n",
    "            \n",
    "            if(use_pca_for_epoching==True):\n",
    "                \n",
    "                raw = apply_pca_to_raw(raw, max_components)\n",
    "                \n",
    "            # Create the Epochs object with preload=True\n",
    "            epochs = mne.Epochs(raw, events1, event_id, tmin=-0.05, tmax=0.05, preload=True, event_repeated='merge')\n",
    "            # Get the events array\n",
    "            events_array = epochs.events\n",
    "            # Get the event_id for 'ULHS'\n",
    "            ulhs_id = event_id['ULHS']\n",
    "            # Count the number of 'ULHS' epochs\n",
    "            num_ulhs = np.sum(events_array[:, 2] == ulhs_id)\n",
    "            #Find continuous no-event epochs\n",
    "            eeg_data.append(epochs)\n",
    "            continuous_no_event_epochs_list = find_continuous_no_event_epochs(events,raw,num_ulhs)\n",
    "            continuous_no_event_epochs_list_all += continuous_no_event_epochs_list\n",
    "            \n",
    "                \n",
    "        elif 'allwalk_artifact.set' in full_path:\n",
    "            if use_78_channels:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "                # randomly select 78 channels\n",
    "                selected_channels = np.random.choice(raw.ch_names, size=78, replace=False)\n",
    "                raw.pick_channels(selected_channels)\n",
    "                # Save the selected channel names to a file\n",
    "                with open(f'{save_dir}/selected_channel_names_{sub_id}.txt', 'w') as f:\n",
    "                    for channel in selected_channels:\n",
    "                        f.write(f'{channel}\\n')\n",
    "                # rename the channels to the same names\n",
    "                channel_names = ['ch' + str(i+1) for i in range(len(raw.ch_names))]\n",
    "                raw.rename_channels(dict(zip(raw.ch_names, channel_names)))\n",
    "\n",
    "\n",
    "            else:\n",
    "                raw = mne.io.read_raw_eeglab(full_path, preload=True)\n",
    "                \n",
    "            events = mne.events_from_annotations(raw)\n",
    "            events1 = events[:1][0]\n",
    "            \n",
    "            if(use_pca_for_epoching==True):\n",
    "                raw = apply_pca_to_raw(raw, max_components)\n",
    "                \n",
    "            epochs = mne.Epochs(raw, events1, event_id=event_id, tmin=-0.05, tmax=0.05, event_repeated='merge')\n",
    "            # Get the events array\n",
    "            events_array = epochs.events\n",
    "            # Get the event_id for 'ULHS'\n",
    "            ulhs_id = event_id['ULHS']\n",
    "            # Count the number of 'ULHS' epochs\n",
    "            num_ulhs = np.sum(events_array[:, 2] == ulhs_id)\n",
    "            #Find continuous no-event epochs\n",
    "            eeg_data.append(epochs)\n",
    "            continuous_no_event_epochs_list = find_continuous_no_event_epochs(events,raw,num_ulhs)\n",
    "            continuous_no_event_epochs_list_all += continuous_no_event_epochs_list\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f'File path for subject {sub_id} is invalid')\n",
    "   \n",
    "\n",
    "    all_data_event = mne.concatenate_epochs(eeg_data)\n",
    "\n",
    "    \n",
    "    # Add the selected no-event epochs to the all epochs list\n",
    "    all_epochs_list = eeg_data + continuous_no_event_epochs_list_all\n",
    "\n",
    "    # Concatenate the event-related and selected no-event epochs\n",
    "    all_data = mne.concatenate_epochs(all_epochs_list)\n",
    "\n",
    "    # Add no_event to the event_id dictionary\n",
    "    event_id['no_event'] = 0\n",
    "\n",
    "    # Save the epoched data for each event type including the no-event epochs\n",
    "    for event_id1 in event_id:\n",
    "        save_path = f'{save_dir}/my_epochs_{event_id1}-epo.fif'\n",
    "        all_data[event_id1].save(save_path, overwrite=True)\n",
    "\n",
    "    return all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
