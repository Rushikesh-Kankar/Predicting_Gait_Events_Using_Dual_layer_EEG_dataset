{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c737ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import mne\n",
    "import os\n",
    "\n",
    "def predict_events1(raw_data, model_path, window_size=0.103515625, step_size=0.001953125, t_min=None, t_max=None, threshold=0.2, n_jobs=14):\n",
    "    \"\"\"\n",
    "    Predicts the events for a given raw data using a trained machine learning model.\n",
    "\n",
    "    Parameters:\n",
    "    raw_data (mne.io.Raw): The raw data to predict events for.\n",
    "    model_path (str): The path to the trained machine learning model file.\n",
    "    window_size (float): The size of the sliding window used for predictions (in seconds). Default is 0.201171875.\n",
    "    step_size (float): The step size used for sliding the window (in seconds). Default is 0.001953125.\n",
    "    t_min (float): The minimum time value to start the sliding window. Default is None (use the beginning of the data).\n",
    "    t_max (float): The maximum time value to end the sliding window. Default is None (use the end of the data).\n",
    "    threshold (float): The probability threshold used for classifying events. Default is 0.5.\n",
    "    n_jobs (int): The number of parallel jobs to run. Default is 1 (no parallelization).\n",
    "\n",
    "    Returns:\n",
    "    event_preds_times (numpy.ndarray): An array containing the predicted events and their corresponding times.\n",
    "    \"\"\"\n",
    "    # Load the trained machine learning model\n",
    "    model = load(model_path)\n",
    "   # print(model)\n",
    "    # Get the time limits of the data\n",
    "    if t_min is None:\n",
    "        t_min = raw_data.times[0]\n",
    "        print(t_min)\n",
    "    if t_max is None:\n",
    "        t_max = raw_data.times[-1]\n",
    "        print(t_max)\n",
    "        \n",
    "    # Set up an empty list to store the predicted events and their times\n",
    "    event_preds = []\n",
    "    event_times = []\n",
    "\n",
    "    # Set up the thread pool executor\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        # Define the predict function to run in parallel\n",
    "        def predict(t_start):\n",
    "            t_end = t_start + window_size\n",
    "\n",
    "            # Extract the data for the current window\n",
    "            data = raw_data.copy().crop(tmin=t_start, tmax=t_end, include_tmax=False).get_data()\n",
    "\n",
    "            # Reshape the data to match the shape expected by the model\n",
    "            data = data.reshape(1, -1)\n",
    "\n",
    "            # Apply the trained machine learning model to predict the probability of each trial belonging to each class\n",
    "            y_pred_proba = model.predict_proba(data)\n",
    "            print(y_pred_proba)\n",
    "\n",
    "            # Assign each trial to the most likely event using a threshold on the predicted probabilities\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1) if np.max(y_pred_proba) > threshold else -1\n",
    "\n",
    "            # Return the predicted event for the current window\n",
    "            if y_pred != -1:\n",
    "                event_pred = y_pred[0]\n",
    "                event_time = (t_start + t_end) / 2\n",
    "                return (event_pred, event_time)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        # Loop over the sliding windows in parallel\n",
    "        futures = []\n",
    "        for t_start in np.arange(t_min, t_max - window_size, step_size):\n",
    "            futures.append(executor.submit(predict, t_start))\n",
    "\n",
    "        # Retrieve the predicted events and their times from the completed futures\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                event_pred = result[0]\n",
    "                event_time = result[1]\n",
    "                event_str = f\"Predicted event: {event_pred}, time: {event_time:.3f}\"\n",
    "                print(event_str)\n",
    "                event_preds.append(event_pred)\n",
    "                event_times.append(event_time)\n",
    "\n",
    "        # Convert the list of predicted events and their times to numpy arrays\n",
    "        event_preds = np.array(event_preds).astype(int)\n",
    "        event_times = np.array(event_times)\n",
    "\n",
    "        # Combine the predicted events and their times into a single DataFrame\n",
    "        df = pd.DataFrame({'event': event_preds, 'time': event_times})\n",
    "        \n",
    "        # Get the base file name of the raw data\n",
    "        raw_file_name = os.path.basename(raw_data.filenames[0])\n",
    "\n",
    "        # Construct the output file name\n",
    "        output_file_name = raw_file_name.split('.')[0] + '_predicted_events.csv'\n",
    "        output_dir = 'Final_Prediction'\n",
    "        # Save the predicted events to a CSV file\n",
    "        df.to_csv(output_dir + '/' + output_file_name, index=False)\n",
    "\n",
    "#         output_dir = 'Final_Prediction'\n",
    "#         output_file = 'predicted_events.csv'\n",
    "#         df.to_csv(os.path.join(output_dir, output_file), index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "def save_event_times(df, output_dir):\n",
    "    # create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # perform the calculations and create the result dataframe\n",
    "    df['event_group'] = (df['event'] != df['event'].shift()).cumsum()\n",
    "    grouped = df.groupby('event_group')\n",
    "    result = grouped.agg({'event': 'first', 'time': ['min', 'max']})\n",
    "    result.columns = ['event', 'start_time', 'end_time']\n",
    "    result['time_occured'] = (result['start_time'] + result['end_time']) / 2\n",
    "    result = result[['event', 'time_occured']]\n",
    "    result.columns = ['event', 'time_occured']\n",
    "\n",
    "    # save the result to a CSV file in the output directory\n",
    "    output_path = os.path.join(output_dir, 'event_times.csv')\n",
    "    result.to_csv(output_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
